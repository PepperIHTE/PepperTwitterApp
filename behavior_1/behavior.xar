<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.ald.softbankrobotics.com/schema/choregraphe/project.xsd" xar_version="3">
  <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
    <bitmap>media/images/box/root.png</bitmap>
    <script language="4">
      <content>
        <![CDATA[]]>
      </content>
    </script>
    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
    <Input name="twitterpepper/confirmation" type="0" type_size="1" nature="4" stm_value_name="twitterpepper/confirmation" inner="1" tooltip="twitterpepper/confirmation desc" id="4" />
    <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="5" />
    <Timeline enable="0">
      <BehaviorLayer name="behavior_layer1">
        <BehaviorKeyframe name="keyframe1" index="1">
          <Diagram>
            <Box name="Python Box" id="2" localization="8" tooltip="" x="607" y="383">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass


    def onInput_input(self, keyword):
        self.logger.info(type(keyword))
        self.logger.info(keyword)
        self.showQuestion(keyword)
        # move
        self.onStopped()




    def onInput_onStop(self):
        self.onUnload()
        self.onStopped()


    def _getTabletService(self):
        tabletService = None
        try:
            tabletService = self.session().service("ALTabletService")
        except Exception as e:
            self.logger.error(e)
        return tabletService


    def _getMemoryService(self):
        service = None
        try:
            service = self.session().service("ALMemory")
        except Exception as e:
            self.logger.error(e)
        return service



    def showQuestion(self, p):
        self._getMemoryService().insertData('keyword', p)
        tabService = self._getTabletService()
        ip = tabService.robotIp()
        uid = self.packageUid()
        url = 'http://' + ip + '/apps/' + uid + '/index.html'
        tabService.loadUrl(url)
        tabService.showWebview()


    def hideQuestion(self):
        tabService = self._getTabletService()
        tabService.hideWebview()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Input name="input" type="3" type_size="1" nature="1" inner="0" tooltip="" id="4" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="5" />
            </Box>
            <Box name="Dialog" id="1" localization="8" tooltip="" x="174" y="0">
              <dialogFile>../topic/topic.dlg</dialogFile>
              <bitmap>media/images/box/box-dialog.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
              <Output name="record" type="1" type_size="1" nature="2" inner="0" tooltip="" id="5" />
              <Output name="stop_record" type="1" type_size="1" nature="2" inner="0" tooltip="" id="6" />
              <Output name="tweet" type="1" type_size="1" nature="2" inner="0" tooltip="" id="7" />
              <Output name="cancel" type="1" type_size="1" nature="2" inner="0" tooltip="" id="8" />
              <Output name="take_picture" type="1" type_size="1" nature="2" inner="0" tooltip="" id="9" />
              <Output name="cance_picture" type="1" type_size="1" nature="2" inner="0" tooltip="" id="10" />
            </Box>
            <Box name="Record Sound" id="3" localization="8" tooltip='Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head microphones) in wav format.&#x0A;&#x0A;If &quot;Temporary storage&quot; isn&apos;t checked, the output sound file is located in &quot;~/recordings/microphones/&lt;File name&gt;&quot;.&#x0A;Else, it is located in a temporary directory&#x0A;&#x0A;The onStopped output is stimulated at the end of the recording and contains the absolute path to the output sound file&#x0A;&#x0A;V1.1.0&#x0A;' x="374" y="5">
              <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
              <Input name="stop" type="1" type_size="1" nature="1" inner="0" tooltip="" id="4" />
              <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="5" />
              <Output name="repeat" type="1" type_size="1" nature="2" inner="0" tooltip="" id="6" />
              <Parameter name="File name" inherits_from_parent="0" content_type="3" value="recording" default_value="recording" custom_choice="0" tooltip="Name of the destination file without its extension." id="7" />
              <Parameter name="Microphones used" inherits_from_parent="0" content_type="3" value="Front head microphone only (.ogg)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="8">
                <Choice value="Front head microphone only (.ogg)" />
                <Choice value="Front, sides and rear head microphones (.wav)" />
              </Parameter>
              <Parameter name="Temporary storage" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is disabled the file is stored in ~/recordings/microphones. You can&#x0A;then get it on your computer using the menu Connection/File transfer.&#x0A;&#x0A;When this option is enabled the file is stored in the temporary folder of the behavior." id="9" />
              <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="20.6906" default_value="5" min="0.1" max="60" tooltip="Duration of the recording in seconds." id="10" />
              <Timeline enable="0">
                <BehaviorLayer name="behavior_layer1">
                  <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram>
                      <Box name="Rec. Sound File" id="4" localization="8" tooltip="Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head&#x0A;microphones) in wav format." x="668" y="155">
                        <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
                        <script language="4">
                          <content>
                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.filepath = ""

    def onLoad(self):
        try:
            self.ad = self.session().service("ALAudioDevice")
        except Exception as e:
            self.ad = None
            self.logger.error(e)
        self.bIsRecording = False
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False
        if( self.bIsRecording ):
            self.ad.stopMicrophonesRecording()
            self.bIsRecording = False

    def onInput_onStart(self, p):
        if(self.bIsRunning):
            return
        self.bIsRunning = True
        sExtension = self.toExtension( self.getParameter("Microphones used") )
        self.filepath = p + sExtension
        if self.ad:
            self.ad.startMicrophonesRecording( self.filepath )
            self.bIsRecording = True
        else:
            self.logger.warning("No sound recorded")

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            ##self.onStopped(self.filepath)

    def onInput_voiceDetected(self):
        self.onUnload()
        self.onStopped(self.filepath)

    def toExtension(self, sMicrophones):
        if( sMicrophones == "Front head microphone only (.ogg)" ):
            return ".ogg"
        else:
            return ".wav"]]>
                          </content>
                        </script>
                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                        <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound. The data received on this input must be the&#x0A;filename of the sound." id="2" />
                        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
                        <Input name="voiceDetected" type="1" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                        <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="5" />
                        <Parameter name="Microphones used" inherits_from_parent="1" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="6">
                          <Choice value="Front head microphone only (.ogg)" />
                          <Choice value="Front, sides and rear head microphones (.wav)" />
                        </Parameter>
                      </Box>
                      <Box name="Get File Name" id="10" localization="8" tooltip="Use this box to choose an attached file in its parameters. The filename will be sent on&#x0A;the output when the input is stimulated." x="233" y="7">
                        <bitmap>media/images/box/folder.png</bitmap>
                        <script language="4">
                          <content>
                            <![CDATA[import os
class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        pass

    def onInput_onStart(self):
        if( self.getParameter("Temporary storage") ):
            import tempfile
            path = tempfile.mkdtemp() + "/"
        else:
            path = os.path.expanduser('~') + "/recordings/microphones/"
        self.onStopped( path + self.getParameter("File name") )]]>
                          </content>
                        </script>
                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                        <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the filepath on the output." id="2" />
                        <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The filepath of the selected resource file." id="3" />
                        <Parameter name="File name" inherits_from_parent="1" content_type="3" value="recording" default_value="" custom_choice="0" tooltip="Name of the file." id="4" />
                        <Parameter name="Temporary storage" inherits_from_parent="1" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is enabled the file is stored in ~/.cache/currentChoregrapheBehavior&#x0A;or in ~/.cache/&lt;project_name&gt; when you play the behavior from the&#x0A;behavior manager.&#x0A;&#x0A;When it is disabled the file is stored in ~/recordedSounds. You can&#x0A;then get it on your computer using the menu Connection/File transfer." id="5" />
                      </Box>
                      <Box name="Wait" id="6" localization="8" tooltip="Wait a moment before sending a signal on the output. &#x0A;Can be stopped anytime. &#x0A;Stimulating the input again before output is activated restarts the waiting period.&#x0A;" x="454" y="0">
                        <bitmap>media/images/box/wait.png</bitmap>
                        <script language="4">
                          <content>
                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.waiting = None

    def onUnload(self):
        self.cancelWaiting()

    def triggerOutput(self):
        self.timerOutput()

    def cancelWaiting(self):
        if self.waiting:
            self.waiting.cancel()
        self.waiting = None

    def onInput_onStart(self):
        self.cancelWaiting()
        import qi
        self.waiting = qi.async(self.triggerOutput, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))

    def onInput_onStop(self):
        if self.getParameter("Trigger timerOutput if cancelled") and self.waiting and self.waiting.isRunning():
            self.timerOutput()
        self.onUnload()]]>
                          </content>
                        </script>
                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Wait box with the configured timeout value." id="2" />
                        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" />
                        <Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once time set in parameters is elapsed, or if the box is stopped and the appropriate parameter is set." id="4" />
                        <Parameter name="Timeout (s)" inherits_from_parent="1" content_type="2" value="5" default_value="5" min="0.1" max="60" tooltip="Duration the box waits before stimulating the output." id="5" />
                        <Parameter name="Trigger timerOutput if cancelled" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="If the box is currently waiting and cancelled, output will be stimulated." id="6" />
                      </Box>
                      <Link inputowner="10" indexofinput="2" outputowner="0" indexofoutput="2" />
                      <Link inputowner="4" indexofinput="2" outputowner="10" indexofoutput="3" />
                      <Link inputowner="6" indexofinput="2" outputowner="10" indexofoutput="3" />
                      <Link inputowner="4" indexofinput="3" outputowner="6" indexofoutput="4" />
                      <Link inputowner="0" indexofinput="6" outputowner="6" indexofoutput="4" />
                      <Link inputowner="4" indexofinput="4" outputowner="0" indexofoutput="4" />
                      <Link inputowner="0" indexofinput="5" outputowner="4" indexofoutput="5" />
                    </Diagram>
                  </BehaviorKeyframe>
                </BehaviorLayer>
              </Timeline>
              <Resource name="Audio recorder" type="Lock" timeout="0" />
            </Box>
            <Box name="ParseFile" id="4" localization="8" tooltip="" x="552" y="0">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[language_codes = {
    "English":"en-US",
    "Finnish":"fi"
}

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        import sys
        sys.path.append("/home/nao")

        self.tweet_str = ""
        import json
        from twitter import *
        with open("/home/nao/.auth/twitter_keys.json") as file:
            keys = json.load(file)
        token = keys["token"]
        token_secret = keys["token_secret"]
        consumer_key = keys["consumer_key"]
        consumer_secret = keys["consumer_secret"]
        self.t = Twitter(auth=OAuth(token, token_secret, consumer_key, consumer_secret))
        self.t_upload = Twitter(domain='upload.twitter.com', auth=OAuth(token, token_secret, consumer_key, consumer_secret))
        self.picture_path = None

        self.tts = self.session().service('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        import speech_recognition as sr
        recorder = sr.Recognizer()
        self.logger.info(p)
        data = sr.AudioFile(p)
        key = None
        language = self.tts.getLanguage()
        l_code = language_codes[language]
        with data as source:
            audio = recorder.record(source)
        text = str(recorder.recognize_google(audio, language=l_code))
        if len(text) > 0:
            self.tweet_str = text
            self.text_output(text)
        else:
            self.logger.info("No text was parsed")

    def onInput_tweet(self):
        if(self.picture_path != None):
            with open(self.picture_path, "rb") as file:
                imagedata = file.read()
            id_img1 = self.t_upload.media.upload(media=imagedata)["media_id_string"]
            self.t.statuses.update(status=self.tweet_str, media_ids=",".join([id_img1]))
            self.picture_path = None
        else:
            self.t.statuses.update(status=self.tweet_str)

        self.ready(self.tweet_str)

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box

    def onInput_picture(self, p):
        self.picture_path = p

    def onInput_remove_picture(self):
        self.picture_path = None]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Input name="tweet" type="1" type_size="1" nature="1" inner="0" tooltip="" id="4" />
              <Input name="picture" type="3" type_size="1" nature="1" inner="0" tooltip="" id="5" />
              <Input name="remove_picture" type="1" type_size="1" nature="1" inner="0" tooltip="" id="6" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="7" />
              <Output name="text_output" type="3" type_size="1" nature="2" inner="0" tooltip="" id="8" />
              <Output name="ready" type="3" type_size="1" nature="2" inner="0" tooltip="" id="9" />
            </Box>
            <Box name="Say Text" id="5" localization="8" tooltip="Say the text received on its input." x="782" y="7">
              <bitmap>media/images/box/interaction/say.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.replies = {
            "Finnish":"Tahdotko tviitata tekstin.",
            "English":"Would you like me to tweet."
        }

    def onLoad(self):
        self.tts = self.session().service('ALTextToSpeech')
        self.ttsStop = self.session().service('ALTextToSpeech') #Create another service as wait is blocking if audioout is remote
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            reply = self.replies[self.tts.getLanguage()]
            id = self.tts.pCall("say",reply)
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.pCall("say",str(sentence))
            self.ids.append(id)
            self.tts.wait(id)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
              <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
              <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
              <Resource name="Speech" type="Lock" timeout="0" />
            </Box>
            <Box name="Say Text (1)" id="9" localization="8" tooltip="Say the text received on its input." x="360" y="386">
              <bitmap>media/images/box/interaction/say.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import time



class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.replies = {
            "Finnish":"Tviittasin tekstin",
            "English":"I tweeted"
        }

    def onLoad(self):
        self.tts = self.session().service('ALTextToSpeech')
        self.ttsStop = self.session().service('ALTextToSpeech') #Create another service as wait is blocking if audioout is remote
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            reply = self.replies[self.tts.getLanguage()]
            id = self.tts.pCall("say",reply)
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.pCall("say",str(sentence))
            self.ids.append(id)
            self.tts.wait(id)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
              <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
              <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
              <Resource name="Speech" type="Lock" timeout="0" />
            </Box>
            <Box name="Raise Event" id="6" localization="8" tooltip="Stores in NAOqi&apos;s shared memory the given value at the given key, and spreads the event to all its subscribers." x="926" y="7">
              <bitmap>media/images/box/sensors/STM.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        pass

    def onLoad(self):
        self.memory = self.session().service("ALMemory")

    def onUnload(self):
        self.memory = None

    def onInput_onStart(self, p):
        self.memory.raiseEvent(self.getParameter("key"), p)
        self.onStopped(p)

    def onInput_onStop(self):
        self.onUnload() #~ it is recommended to call onUnload of this box in a onStop method, as the code written in onUnload is used to stop the box as well
        pass]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Receives the value to be inserted as an event in ALMemory." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="0" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished. It contains the inserted value in ALMemory." id="4" />
              <Output name="onError" type="3" type_size="1" nature="1" inner="0" tooltip="Output when error is raised by the behavior. Contains the error message." id="5" />
              <Parameter name="key" inherits_from_parent="0" content_type="3" value="twitterpepper/confirmation" default_value="MyApplication/MyData" custom_choice="0" tooltip="" id="6" />
            </Box>
            <Box name="Take Picture" id="7" localization="8" tooltip="Take a picture with one of the cameras camera and store it in his memory in ~/recordings/cameras. The image format is JPG.&#x0A;&#x0A;V1.1.0&#x0A;" x="373" y="139">
              <bitmap>media/images/box/interaction/picture.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.resolutionMap = {
            '160 x 120': 0,
            '320 x 240': 1,
            '640 x 480': 2,
            '1280 x 960': 3
        }
        self.cameraMap = {
            'Top': 0,
            'Bottom': 1
        }

        self.recordFolder = "/home/nao/recordings/cameras/"

    def onLoad(self):
        self.bIsRunning = False
        try:
            self.photoCapture = self.session().service( "ALPhotoCapture" )
        except Exception as e:
            self.photoCapture = None
            self.logger.error(e)

    def onUnload(self):
        pass

    def onInput_onStart(self):
        if( self.bIsRunning ):
            return
        self.bIsRunning = True
        resolution = self.resolutionMap[self.getParameter("Resolution")]
        cameraID = self.cameraMap[self.getParameter("Camera")]
        fileName = self.getParameter("File Name")
        if self.photoCapture:
            self.photoCapture.setResolution(resolution)
            self.photoCapture.setCameraID(cameraID)
            self.photoCapture.setPictureFormat("jpg")
            self.photoCapture.takePicture( self.recordFolder, fileName )
        self.bIsRunning = False
        self.onStopped(self.recordFolder + fileName + ".jpg")]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
              <Parameter name="Resolution" inherits_from_parent="0" content_type="3" value="640 x 480" default_value="640 x 480" custom_choice="0" tooltip="Image resolution." id="4">
                <Choice value="160 x 120" />
                <Choice value="320 x 240" />
                <Choice value="640 x 480" />
                <Choice value="1280 x 960" />
              </Parameter>
              <Parameter name="File Name" inherits_from_parent="0" content_type="3" value="image" default_value="image" custom_choice="0" tooltip="Name of the file without its extension." id="5" />
              <Parameter name="Camera" inherits_from_parent="0" content_type="3" value="Top" default_value="Top" custom_choice="0" tooltip="Enables to select the camera (Top or Bottom) that will take the picture." id="6">
                <Choice value="Top" />
                <Choice value="Bottom" />
              </Parameter>
            </Box>
            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" />
            <Link inputowner="3" indexofinput="2" outputowner="1" indexofoutput="5" />
            <Link inputowner="3" indexofinput="4" outputowner="1" indexofoutput="6" />
            <Link inputowner="3" indexofinput="2" outputowner="3" indexofoutput="6" />
            <Link inputowner="4" indexofinput="2" outputowner="3" indexofoutput="5" />
            <Link inputowner="5" indexofinput="2" outputowner="4" indexofoutput="8" />
            <Link inputowner="9" indexofinput="2" outputowner="4" indexofoutput="9" />
            <Link inputowner="6" indexofinput="2" outputowner="5" indexofoutput="4" />
            <Link inputowner="4" indexofinput="4" outputowner="1" indexofoutput="7" />
            <Link inputowner="1" indexofinput="2" outputowner="9" indexofoutput="4" />
            <Link inputowner="1" indexofinput="2" outputowner="1" indexofoutput="8" />
            <Link inputowner="7" indexofinput="2" outputowner="1" indexofoutput="9" />
            <Link inputowner="4" indexofinput="5" outputowner="7" indexofoutput="3" />
            <Link inputowner="4" indexofinput="6" outputowner="1" indexofoutput="10" />
          </Diagram>
        </BehaviorKeyframe>
      </BehaviorLayer>
    </Timeline>
  </Box>
</ChoregrapheProject>
